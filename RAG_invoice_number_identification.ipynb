{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import pandas\n",
    "import re\n",
    "import chromadb.config\n",
    "import chromadb.types\n",
    "\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "from PIL import Image\n",
    "from pytesseract import image_to_string\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_embedding_function():    \n",
    "    embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "    \n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_text(pdf_file, output_file):\n",
    "    images = convert_from_path(pdf_file)\n",
    "    final_text = \"\"\n",
    "    for img in images:\n",
    "        final_text += image_to_string(img)\n",
    "        # print(final_text)\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(final_text)\n",
    "data_paths =[\"example_invoice1.pdf\", \"example_invoice2.pdf\", \"example_invoice3.pdf\"]\n",
    "invoice_numbers=[['1234567'], ['R/1243737'], ['RE22000188', '203857593']]\n",
    "output_file = \"extracted_text.txt\"\n",
    "invoice_numbers_detected=[]\n",
    "model = Ollama(model=\"llama3-chatqa\", temperature=0.01)\n",
    "template = \"\"\"\n",
    "        <|System|>>\n",
    "    You are a very helpful AI assistant who follows instructions very well.\n",
    "    Use the following context to answer the question.\n",
    "\n",
    "    Think step-by-step and carefully review the document provided before responding. You will receive $100 if you answer the question correctly.\n",
    "\n",
    "    Make sure to respond only with the invoice number(s) and no additional text!\n",
    "\n",
    "\n",
    "    Kontext: {context}\n",
    "    </s>\n",
    "    <|user|>\n",
    "    {query}\n",
    "    </s>\n",
    "    <|Assistent|>\n",
    "    \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoice Number Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_documents(data_paths_subset):\n",
    "    # List to store extracted invoice numbers\n",
    "    invoice_numbers_detected = []\n",
    "    \n",
    "    # Loop through each file in the provided subset\n",
    "    for i, data_path in enumerate(data_paths_subset):\n",
    "        output_file = f\"extracted_text_part{i}.txt\"\n",
    "\n",
    "        # Convert PDF to plain text and save to file\n",
    "        pdf_to_text(data_path, output_file)\n",
    "\n",
    "        # Load the extracted text\n",
    "        loader = TextLoader(output_file)\n",
    "        docs = loader.load()\n",
    "\n",
    "        # Split text into overlapping chunks for retrieval\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=100)\n",
    "        chunks = splitter.split_documents(docs)\n",
    "        print(chunks)\n",
    "\n",
    "        # Create a vectorstore (Chroma) from the chunks using embedding function\n",
    "        vectorstore = Chroma.from_documents(chunks, get_embedding_function())\n",
    "        \n",
    "        # Define two types of retrievers: dense (vector-based) and sparse (BM25)\n",
    "        vectorstore_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "        keyword_retriever = BM25Retriever.from_documents(chunks)\n",
    "        keyword_retriever.k = 1\n",
    "\n",
    "        # Combine both retrievers into an ensemble with custom weights\n",
    "        ensemble_retriever = EnsembleRetriever(\n",
    "            retrievers=[vectorstore_retriever, keyword_retriever],\n",
    "            weights=[0.1, 0.9]\n",
    "        )\n",
    "\n",
    "        # Set up the output parser and prompt\n",
    "        output_parser = StrOutputParser()\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "        # Create the processing chain: retrieval → prompt → model → output parsing\n",
    "        chain = (\n",
    "            {\"context\": ensemble_retriever, \"query\": RunnablePassthrough()}\n",
    "            | prompt\n",
    "            | model\n",
    "            | output_parser\n",
    "        )\n",
    "\n",
    "        # Execute the chain with a predefined task prompt\n",
    "        response = chain.invoke(\"\"\"\n",
    "            Task: A reminder needs to be analyzed. The goal is to identify and extract the invoice numbers. \n",
    "            The invoice number is often a number of 6–12 numeric or alphanumeric digits. Also look for letters such as \"RE\" or \"AR\" as part of the number or \n",
    "            separated with the numbers by \"/\" or \"-\".  \n",
    "            \n",
    "            Look for terms like \"Invoice Number\", \"Invoice No.\", \"Beleg\", \"Belegnummer\", or similar nearby or in a table.                         \n",
    "            There may be multiple invoice numbers in a document, and you should recognize all of them. \n",
    "            \n",
    "            If there is more than one invoice number in a document, make sure to split them with a comma.                                \n",
    "            Make sure to respond only with the invoice number(s) and avoid any additional text or \"None\" as an answer. \n",
    "            \n",
    "            Which invoice numbers do you find in the document?\n",
    "        \"\"\")\n",
    "\n",
    "        # Store the response\n",
    "        invoice_numbers_detected.append(response)\n",
    "\n",
    "        # Cleanup: delete entries from the vectorstore and release memory\n",
    "        ids = vectorstore.get(where={'source': output_file})['ids']\n",
    "        vectorstore.delete(ids)\n",
    "        del vectorstore\n",
    "\n",
    "    return invoice_numbers_detected\n",
    "\n",
    "# Process all documents in the provided data_paths list\n",
    "invoices_results = process_documents(data_paths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(nested_list):\n",
    "    \"\"\" Flacht eine verschachtelte Liste zu einer einfachen Liste ab. \"\"\"\n",
    "    flat_list = []\n",
    "    for element in nested_list:\n",
    "        if isinstance(element, list):\n",
    "            flat_list.extend(flatten_list(element))  # Rekursiv für Listen\n",
    "        else:\n",
    "            flat_list.append(element)\n",
    "    return flat_list\n",
    "\n",
    "def split_and_flatten(numbers_list):\n",
    "    \"\"\" Spaltet Strings in einer Liste auf, die durch Kommas getrennte Nummern enthalten. \"\"\"\n",
    "    flattened_list = []\n",
    "    for item in numbers_list:\n",
    "        split_items = item.split(',')\n",
    "        split_items = [num.strip() for num in split_items]  # Entfernen von zusätzlichen Leerzeichen\n",
    "        flattened_list.extend(split_items)\n",
    "    return flattened_list\n",
    "\n",
    "# Verarbeite die tatsächlichen Rechnungsnummern und die Ausgabe des LLM\n",
    "flat_invoice_numbers = flatten_list(invoice_numbers)\n",
    "processed_output = split_and_flatten(invoices_results)\n",
    "\n",
    "# Umwandeln in Mengen und Berechnung der Schnittmenge\n",
    "set_actual_numbers = set(flat_invoice_numbers)\n",
    "set_detected_numbers = set(processed_output)\n",
    "intersection = set_actual_numbers.intersection(set_detected_numbers)\n",
    "\n",
    "# Berechnung und Ausgabe der Genauigkeit\n",
    "accuracy = len(intersection) / len(set_actual_numbers) * 100\n",
    "print(f\"Anzahl der korrekt erkannten Rechnungsnummern: {len(intersection)}\")\n",
    "print(\"Korrekt erkannte Rechnungsnummern:\", intersection)\n",
    "print(f\"Genauigkeit der Erkennung: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "correct_classifications = 47\n",
    "incorrect_classifications = 51\n",
    "# Data for RAG model results\n",
    "labels = ['Correctly Classified', 'Incorrectly Classified']\n",
    "counts = [correct_classifications, incorrect_classifications]\n",
    "\n",
    "# Creating the bar chart\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(labels, counts, color=['green', 'red'])\n",
    "ax.set_ylabel('Number of Invoice Numbers')\n",
    "ax.set_title('RAG Model Classification Results')\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use LlamaParse to improve the Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables \n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Patch asyncio to work inside notebooks or nested environments\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "# Load the API key for LlamaParse (optional if set via .env)\n",
    "llamaparse_api_key = os.getenv(\"LLAMA_CLOUD_API_KEY\")\n",
    "\n",
    "# Configure the PDF parser\n",
    "parser = LlamaParse(\n",
    "    api_key=\"\",  # use your actual key \n",
    "    result_type=\"markdown\"  # formats: \"markdown\" or \"text\"\n",
    ")\n",
    "\n",
    "# Parse the input document(s) using the parser\n",
    "file_extractor = {\".pdf\": parser}\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"example_invoice1.pdf\"],  # update with your PDF filename(s)\n",
    "    file_extractor=file_extractor\n",
    ").load_data()\n",
    "\n",
    "# === Embedding and LLM Setup ===\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# Use Ollama for both embedding and language model\n",
    "embed_model = OllamaEmbedding(model_name=\"llama3\")\n",
    "llm = Ollama(model=\"llama3\", request_timeout=30.0)\n",
    "\n",
    "# Apply settings globally\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm\n",
    "\n",
    "# === Indexing and Query Engine Setup ===\n",
    "\n",
    "# Create a vector-based index from the parsed documents\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# Create a query engine based on the index\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "\n",
    "# Prompt to extract invoice numbers\n",
    "query = (\n",
    "    \"Please analyze the full document, including all text sections and tables. \"\n",
    "    \"Extract every invoice number mentioned in the document. \"\n",
    "    \"Invoice numbers are usually 6–12 digits, sometimes including slashes or dashes (e.g. RE-2023/0921). \"\n",
    "    \"Use keywords like 'Invoice Number', 'Rechnungsnummer', 'Beleg', etc. \"\n",
    "    \"List all invoice numbers found, separated by a comma. Do not include any other text.\"\n",
    ")\n",
    "\n",
    "# Run the query against the document index\n",
    "response = query_engine.query(query)\n",
    "\n",
    "# Display extracted invoice numbers\n",
    "print(\"Extracted Invoice Numbers:\")\n",
    "print(response)\n",
    "\n",
    "# === (Optional) Ground Truth Comparison ===\n",
    "\n",
    "# Define the correct/expected invoice numbers for this document\n",
    "ground_truth = {\"RE-2023/0921\", \"INV-001237\", \"AB123456\"}\n",
    "\n",
    "# Convert model output into set of strings for comparison\n",
    "predicted_numbers = set(str(response).replace(\" \", \"\").split(\",\"))\n",
    "\n",
    "# Evaluate model performance\n",
    "true_positives = predicted_numbers & ground_truth\n",
    "false_positives = predicted_numbers - ground_truth\n",
    "false_negatives = ground_truth - predicted_numbers\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
